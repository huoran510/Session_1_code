{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09575d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2168\n",
      "Recall: 0.2804\n",
      "F1 Score: 0.2445\n",
      "Confusion Matrix:\n",
      "[[19980   542]\n",
      " [  385   150]]\n"
     ]
    }
   ],
   "source": [
    "# For target_1 \"at_risk_event\".\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "data = pd.read_csv('D:/dissertation/session 1/feature.csv')\n",
    "\n",
    "# Define the features that will be used by the models.\n",
    "features = ['is_non_working_hour', 'is_weekend', 'adjusted_non_working_hour_risk_normalized',\n",
    "            'adjusted_weekend_risk_normalized', 'first_non_working_hour', 'first_weekend', \n",
    "            'time_to_working_hour_normalized', 'spend_normalized', 'spend_diff_flag']\n",
    "\n",
    "# Define specific parameters for One-Class SVM that will be used for each cluster.\n",
    "params = {\n",
    "    0: {'nu': 0.03, 'kernel': 'rbf', 'gamma': 'auto'},\n",
    "    1: {'nu': 0.03, 'kernel': 'rbf', 'gamma': 'auto'},\n",
    "    2: {'nu': 0.04, 'kernel': 'rbf', 'gamma': 'auto'}\n",
    "}\n",
    "\n",
    "results = []\n",
    "test_results = []\n",
    "\n",
    "for cluster in data['cluster_label'].unique():\n",
    "    # Filter data for each cluster.\n",
    "    cluster_data = data[data['cluster_label'] == cluster]\n",
    "\n",
    "    # Select features and target variable.\n",
    "    X = cluster_data[features]\n",
    "    y = cluster_data['at_risk_event'].apply(lambda x: 1 if x else 0)  # 确保标签正确转换\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split data into training and test sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize One-Class SVM with parameters specific to the cluster.\n",
    "    oc_svm = OneClassSVM(**params[cluster])\n",
    "\n",
    "    # Train the model on the training data.\n",
    "    oc_svm.fit(X_train)\n",
    "\n",
    "    # Predict on the test set.\n",
    "    y_pred_test = oc_svm.predict(X_test)\n",
    "    y_pred_test = [0 if x == 1 else 1 for x in y_pred_test]\n",
    "\n",
    "    # Append the test results for evaluation.\n",
    "    test_results.append(pd.DataFrame({\n",
    "        'true_label': y_test,\n",
    "        'predicted_label': y_pred_test\n",
    "    }))\n",
    "\n",
    "# Combine all test results into a single DataFrame for evaluation.\n",
    "final_test_results = pd.concat(test_results)\n",
    "\n",
    "# Calculate and print performance metrics.\n",
    "precision = precision_score(final_test_results['true_label'], final_test_results['predicted_label'])\n",
    "recall = recall_score(final_test_results['true_label'], final_test_results['predicted_label'])\n",
    "f1 = f1_score(final_test_results['true_label'], final_test_results['predicted_label'])\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print the confusion matrix.\n",
    "conf_matrix = confusion_matrix(final_test_results['true_label'], final_test_results['predicted_label'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca9d019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['scores'] = ocsvm.decision_function(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = ocsvm.predict(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['scores'] = ocsvm.decision_function(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = ocsvm.predict(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['scores'] = ocsvm.decision_function(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = ocsvm.predict(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_9948\\1681223035.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# For target_2 \"at_risk_event\".\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "data = pd.read_csv('D:/dissertation/session 1/feature.csv')\n",
    "\n",
    "# Define model parameters for One-Class SVM for each cluster.\n",
    "params = {\n",
    "    0: {'kernel': 'rbf', 'nu': 0.01, 'gamma': 'auto'},\n",
    "    1: {'kernel': 'rbf', 'nu': 0.01, 'gamma': 'auto'},\n",
    "    2: {'kernel': 'rbf', 'nu': 0.02, 'gamma': 'auto'}\n",
    "}\n",
    "\n",
    "# Define the list of features that will be used in the anomaly detection model.\n",
    "features = ['is_non_working_hour', 'is_weekend', 'prob_non_working_hours_normalized', 'prob_weekend_normalized',\n",
    "            'first_and_second_non_working_hour', 'first_and_second_weekend', \n",
    "            'spend_normalized', 'spend_diff', 'spend_diff_flag', 'first_two_high_spend']\n",
    "\n",
    "test_results = []\n",
    "\n",
    "# Split the dataset by cluster label and train One-Class SVM for each cluster.\n",
    "for cluster_label in data['cluster_label'].unique():\n",
    "    cluster_data = data[data['cluster_label'] == cluster_label]\n",
    "\n",
    "    # Train the One-Class SVM model using the defined parameters for the cluster.\n",
    "    ocsvm = OneClassSVM(**params[cluster_label])\n",
    "    ocsvm.fit(cluster_data[features])\n",
    "    \n",
    "    # Predict anomalies and calculate decision function scores.\n",
    "    cluster_data['scores'] = ocsvm.decision_function(cluster_data[features])\n",
    "    cluster_data['outlier_label'] = ocsvm.predict(cluster_data[features])\n",
    "\n",
    "    # Convert the outlier labels from -1 and 1 to 1 and 0.\n",
    "    cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n",
    "\n",
    "    # Save the prediction results for further analysis.\n",
    "    test_results.append(cluster_data)\n",
    "\n",
    "# Combine the results from all clusters into a single DataFrame.\n",
    "final_test_data = pd.concat(test_results)\n",
    "\n",
    "final_test_data['date'] = pd.to_datetime(final_test_data['date'])\n",
    "final_test_data.sort_values(by=['individual_id', 'date'], inplace=True)\n",
    "final_test_data['window_id'] = pd.NA\n",
    "final_test_data['processed_flag'] = False\n",
    "\n",
    "# Detect and mark anomaly windows.\n",
    "window_id = 0\n",
    "for index, row in final_test_data.iterrows():\n",
    "    if row['outlier_label'] == 1 and not row['processed_flag']:\n",
    "        current_datetime = row['date']\n",
    "        end_datetime = current_datetime + pd.Timedelta(days=4)\n",
    "        \n",
    "        # Select records within a 5-day window.\n",
    "        mask = (final_test_data['individual_id'] == row['individual_id']) & \\\n",
    "               (final_test_data['date'] >= current_datetime) & \\\n",
    "               (final_test_data['date'] <= end_datetime)\n",
    "        \n",
    "        # Start marking from the current record to ensure the window starts from the current anomaly.\n",
    "        current_record_index = final_test_data[(final_test_data['individual_id'] == row['individual_id']) & \\\n",
    "                                               (final_test_data['date'] == current_datetime)].index\n",
    "        start_index = current_record_index[current_record_index >= index][0]\n",
    "        \n",
    "        mask = (mask) & (final_test_data.index >= start_index)\n",
    "        \n",
    "        # Assign a window ID to all records within the window and mark them as processed.\n",
    "        final_test_data.loc[mask, 'window_id'] = window_id\n",
    "        final_test_data.loc[mask, 'processed_flag'] = True\n",
    "        window_id += 1\n",
    "\n",
    "final_test_data.drop(columns=['processed_flag'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a425f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_target_eval_func(df,\n",
    "                            second_target_pred_col_name=\"second_target_pred\",\n",
    "                            at_risk_behaviour_window_col_name=\"at_risk_behaviour_window\"):\n",
    "    \"\"\"\n",
    "    Evaluate the predictions for the second target, at_risk_behaviour_window.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): the dataframe with your predictions and the target window.\n",
    "        second_target_pred_col_name (string): the name of the column with your predictions.\n",
    "        at_risk_behaviour_window_col_name (string): the name of the column with the target window.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: the original dataframe with 2 additional columns:\n",
    "            target_window_found: has value True if window found, False if window wasnt found, NaN if event isnt in a window;\n",
    "            correct_predictions: has value True if prediction was in a window, False if outside, NaN if no prediction made.\n",
    "        float: precision.\n",
    "        float: recall.\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Identify the windows found.\n",
    "    windows_found = df_copy.groupby(at_risk_behaviour_window_col_name).agg({second_target_pred_col_name:\"max\"})[second_target_pred_col_name]\n",
    "    windows_missed = ~windows_found\n",
    "\n",
    "    # Join the windows found with the df.\n",
    "    df_copy = pd.merge(df_copy, pd.DataFrame(windows_found), left_on=at_risk_behaviour_window_col_name, right_index=True, how=\"left\", suffixes=(\"\", \"_found\"))\n",
    "    df_copy = df_copy.rename(columns={second_target_pred_col_name + \"_found\":\"target_window_found\"})\n",
    "\n",
    "    # Identify the events where a prediction was correctly or incorrectly made.\n",
    "    correct_predictions = df_copy[df_copy[second_target_pred_col_name]][at_risk_behaviour_window_col_name].notna()\n",
    "    df_copy[\"correct_predictions\"] = correct_predictions\n",
    "    num_predictions = sum(df_copy[second_target_pred_col_name])\n",
    "    missed_predictions = (correct_predictions == False).sum()\n",
    "\n",
    "    # Calculate metrics.\n",
    "    \"\"\"\n",
    "    TP is the number of windows correctly identified.\n",
    "    FP is the number of predictions made incorrectly.\n",
    "    Additional predictions made for a window after the first do not affect the precision or recall (ie the FP wont change).\n",
    "    \"\"\"\n",
    "    TP = windows_found.sum()\n",
    "    FP = missed_predictions\n",
    "    support = len(windows_found)\n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/support\n",
    "\n",
    "    return df_copy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1585ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_window_id(row):\n",
    "    if not pd.isna(row['window_id']):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "final_test_data[\"my_pred_column\"] = final_test_data.apply(lambda row: check_window_id(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cacbc015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of OCSVM: 0.03764225269915378 recall of OCSVM: 0.1419141914191419\n"
     ]
    }
   ],
   "source": [
    "df_with_pred_evaluations, precision, recall = second_target_eval_func(df=final_test_data,\n",
    "                                                                      second_target_pred_col_name=\"my_pred_column\")\n",
    "\n",
    "print(\"precision of OCSVM:\", precision, \"recall of OCSVM:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76cf91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
