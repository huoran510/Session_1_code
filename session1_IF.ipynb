{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f55ac3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3757\n",
      "Recall: 0.5084\n",
      "F1 Score: 0.4321\n",
      "Confusion Matrix:\n",
      "[[20070   452]\n",
      " [  263   272]]\n"
     ]
    }
   ],
   "source": [
    "# For target_1 \"at_risk_event\".\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "data = pd.read_csv('D:/dissertation/session 1/feature.csv')\n",
    "\n",
    "# Split the dataset into three parts based on the cluster label.\n",
    "data_0 = data[data['cluster_label'] == 0]\n",
    "data_1 = data[data['cluster_label'] == 1]\n",
    "data_2 = data[data['cluster_label'] == 2]\n",
    "\n",
    "# Define model parameters tailored for each cluster.\n",
    "params = {\n",
    "    0: {'n_estimators': 200, 'max_samples': 'auto', 'contamination': 0.03, 'random_state': 42},\n",
    "    1: {'n_estimators': 200, 'max_samples': 'auto', 'contamination': 0.03, 'random_state': 42},\n",
    "    2: {'n_estimators': 200, 'max_samples': 'auto', 'contamination': 0.04, 'random_state': 42}\n",
    "}\n",
    "\n",
    "# List of features to use in the model.\n",
    "features = ['is_non_working_hour', 'is_weekend', 'adjusted_non_working_hour_risk_normalized', \n",
    "            'adjusted_weekend_risk_normalized', 'first_non_working_hour', 'first_weekend', \n",
    "            'time_to_working_hour_normalized', 'spend_normalized', 'spend_diff_flag']\n",
    "\n",
    "test_results = []\n",
    "clusters = [data_0, data_1, data_2]\n",
    "cluster_labels = [0, 1, 2]\n",
    "\n",
    "for subset, label in zip(clusters, cluster_labels):\n",
    "    # Split each cluster into training and testing datasets.\n",
    "    X_train, X_test = train_test_split(subset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the Isolation Forest model using the parameters defined above.\n",
    "    iso = IsolationForest(**params[label])\n",
    "    iso.fit(X_train[features])\n",
    "    \n",
    "    # Predict on the testing dataset to identify outliers (anomalies).\n",
    "    X_test['scores'] = iso.decision_function(X_test[features])\n",
    "    X_test['outlier_label'] = iso.predict(X_test[features])\n",
    "    \n",
    "    test_results.append(X_test)\n",
    "\n",
    "# Combine all testing results into a single DataFrame.\n",
    "final_test_data = pd.concat(test_results)\n",
    "\n",
    "# Convert the 'at_risk_event' from Boolean to a binary format suitable for scoring.\n",
    "final_test_data['true_label'] = final_test_data['at_risk_event'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "# Convert the Isolation Forest output from -1 and 1 to 1 and 0 respectively for easier comparison.\n",
    "final_test_data['predicted_label'] = (final_test_data['outlier_label'] == -1).astype(int)\n",
    "\n",
    "# Calculate performance metrics to evaluate the effectiveness of the model.\n",
    "precision = precision_score(final_test_data['true_label'], final_test_data['predicted_label'])\n",
    "recall = recall_score(final_test_data['true_label'], final_test_data['predicted_label'])\n",
    "f1 = f1_score(final_test_data['true_label'], final_test_data['predicted_label'])\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Compute the confusion matrix.\n",
    "conf_matrix = confusion_matrix(final_test_data['true_label'], final_test_data['predicted_label'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fce1baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['scores'] = iso.decision_function(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = iso.predict(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['scores'] = iso.decision_function(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = iso.predict(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['scores'] = iso.decision_function(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = iso.predict(cluster_data[features])\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15312\\1607900082.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# For target_2 \"at_risk_event\".\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "data = pd.read_csv('D:/dissertation/session 1/feature.csv')\n",
    "\n",
    "# Define model parameters for each cluster based on predefined settings.\n",
    "params = {\n",
    "    0: {'n_estimators': 200, 'max_samples': 'auto', 'contamination': 0.01, 'random_state': 42},\n",
    "    1: {'n_estimators': 200, 'max_samples': 'auto', 'contamination': 0.01, 'random_state': 42},\n",
    "    2: {'n_estimators': 200, 'max_samples': 'auto', 'contamination': 0.02, 'random_state': 42}\n",
    "}\n",
    "\n",
    "# Define the list of features that will be used in the model.\n",
    "features = ['is_non_working_hour', 'is_weekend', 'prob_non_working_hours_normalized', 'prob_weekend_normalized',\n",
    "            'first_and_second_non_working_hour', 'first_and_second_weekend', \n",
    "            'spend_normalized', 'spend_diff', 'spend_diff_flag', 'first_two_high_spend']\n",
    "\n",
    "test_results = []\n",
    "\n",
    "# Split the dataset by cluster labels and apply the Isolation Forest model to each cluster.\n",
    "for cluster_label in data['cluster_label'].unique():\n",
    "    cluster_data = data[data['cluster_label'] == cluster_label]\n",
    "\n",
    "    # Train the Isolation Forest model using the specified parameters for the cluster.\n",
    "    iso = IsolationForest(**params[cluster_label])\n",
    "    iso.fit(cluster_data[features])\n",
    "    \n",
    "    # Predict anomalies and calculate decision function scores.\n",
    "    cluster_data['scores'] = iso.decision_function(cluster_data[features])\n",
    "    cluster_data['outlier_label'] = iso.predict(cluster_data[features])\n",
    "\n",
    "    # Convert the outlier labels from -1, 1 to 1, 0.\n",
    "    cluster_data['outlier_label'] = (cluster_data['outlier_label'] == -1).astype(int)\n",
    "\n",
    "    # Save the prediction results for further analysis.\n",
    "    test_results.append(cluster_data)\n",
    "\n",
    "# Combine the results from all clusters into a single DataFrame.\n",
    "final_test_data = pd.concat(test_results)\n",
    "\n",
    "final_test_data['date'] = pd.to_datetime(final_test_data['date'])\n",
    "final_test_data.sort_values(by=['individual_id', 'date'], inplace=True)\n",
    "\n",
    "# Initialize window_id as NA and processed_flag as False for new data marking.\n",
    "final_test_data['window_id'] = pd.NA\n",
    "final_test_data['processed_flag'] = False\n",
    "\n",
    "# Detect and mark anomaly windows.\n",
    "window_id = 0\n",
    "for index, row in final_test_data.iterrows():\n",
    "    if row['outlier_label'] == 1 and not row['processed_flag']:\n",
    "        current_datetime = row['date']\n",
    "        end_datetime = current_datetime + pd.Timedelta(days=4)\n",
    "        \n",
    "        # Select records within a 5-day window.\n",
    "        mask = (final_test_data['individual_id'] == row['individual_id']) & \\\n",
    "               (final_test_data['date'] >= current_datetime) & \\\n",
    "               (final_test_data['date'] <= end_datetime)\n",
    "        \n",
    "        # Start marking from the current record to ensure the window starts from the first anomalous event.\n",
    "        current_record_index = final_test_data[(final_test_data['individual_id'] == row['individual_id']) & \\\n",
    "                                               (final_test_data['date'] == current_datetime)].index\n",
    "        start_index = current_record_index[current_record_index >= index][0]\n",
    "        \n",
    "        mask = (mask) & (final_test_data.index >= start_index)\n",
    "        \n",
    "        # Assign window ID to all records within the window and mark them as processed.\n",
    "        final_test_data.loc[mask, 'window_id'] = window_id\n",
    "        final_test_data.loc[mask, 'processed_flag'] = True\n",
    "        window_id += 1\n",
    "\n",
    "final_test_data.drop(columns=['processed_flag'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dceceb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_target_eval_func(df,\n",
    "                            second_target_pred_col_name=\"second_target_pred\",\n",
    "                            at_risk_behaviour_window_col_name=\"at_risk_behaviour_window\"):\n",
    "    \"\"\"\n",
    "    Evaluate the predictions for the second target, at_risk_behaviour_window.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): the dataframe with your predictions and the target window.\n",
    "        second_target_pred_col_name (string): the name of the column with your predictions.\n",
    "        at_risk_behaviour_window_col_name (string): the name of the column with the target window.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: the original dataframe with 2 additional columns:\n",
    "            target_window_found: has value True if window found, False if window wasnt found, NaN if event isnt in a window;\n",
    "            correct_predictions: has value True if prediction was in a window, False if outside, NaN if no prediction made.\n",
    "        float: precision.\n",
    "        float: recall.\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Identify the windows found.\n",
    "    windows_found = df_copy.groupby(at_risk_behaviour_window_col_name).agg({second_target_pred_col_name:\"max\"})[second_target_pred_col_name]\n",
    "    windows_missed = ~windows_found\n",
    "\n",
    "    # Join the windows found with the df.\n",
    "    df_copy = pd.merge(df_copy, pd.DataFrame(windows_found), left_on=at_risk_behaviour_window_col_name, right_index=True, how=\"left\", suffixes=(\"\", \"_found\"))\n",
    "    df_copy = df_copy.rename(columns={second_target_pred_col_name + \"_found\":\"target_window_found\"})\n",
    "\n",
    "    # Identify the events where a prediction was correctly or incorrectly made.\n",
    "    correct_predictions = df_copy[df_copy[second_target_pred_col_name]][at_risk_behaviour_window_col_name].notna()\n",
    "    df_copy[\"correct_predictions\"] = correct_predictions\n",
    "    num_predictions = sum(df_copy[second_target_pred_col_name])\n",
    "    missed_predictions = (correct_predictions == False).sum()\n",
    "\n",
    "    # Calculate metrics.\n",
    "    \"\"\"\n",
    "    TP is the number of windows correctly identified.\n",
    "    FP is the number of predictions made incorrectly.\n",
    "    Additional predictions made for a window after the first do not affect the precision or recall (ie the FP wont change).\n",
    "    \"\"\"\n",
    "    TP = windows_found.sum()\n",
    "    FP = missed_predictions\n",
    "    support = len(windows_found)\n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/support\n",
    "\n",
    "    return df_copy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84af55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_window_id(row):\n",
    "    if not pd.isna(row['window_id']):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "final_test_data[\"my_pred_column\"] = final_test_data.apply(lambda row: check_window_id(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f0bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of IF: 0.04509894155545329 recall of IF: 0.2156215621562156\n"
     ]
    }
   ],
   "source": [
    "df_with_pred_evaluations, precision, recall = second_target_eval_func(df=final_test_data,\n",
    "                                                                      second_target_pred_col_name=\"my_pred_column\")\n",
    "\n",
    "print(\"precision of IF:\", precision, \"recall of IF:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b3394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
